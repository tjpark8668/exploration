{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f665ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ab09ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43729</th>\n",
       "      <td>I'm really in a bind.</td>\n",
       "      <td>Je suis vraiment dans le pétrin.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162794</th>\n",
       "      <td>I'd like to discuss this with your boss.</td>\n",
       "      <td>J'aimerais en discuter avec ton patron.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75321</th>\n",
       "      <td>Tom is reprimanding Mary.</td>\n",
       "      <td>Tom réprimande Marie.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>Please be honest.</td>\n",
       "      <td>Veuillez être honnêtes !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178246</th>\n",
       "      <td>They caught him playing a trick on his sister.</td>\n",
       "      <td>Ils le prirent en train de faire une farce à s...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   eng  \\\n",
       "43729                            I'm really in a bind.   \n",
       "162794        I'd like to discuss this with your boss.   \n",
       "75321                        Tom is reprimanding Mary.   \n",
       "20153                                Please be honest.   \n",
       "178246  They caught him playing a trick on his sister.   \n",
       "\n",
       "                                                      fra  \\\n",
       "43729                    Je suis vraiment dans le pétrin.   \n",
       "162794            J'aimerais en discuter avec ton patron.   \n",
       "75321                               Tom réprimande Marie.   \n",
       "20153                            Veuillez être honnêtes !   \n",
       "178246  Ils le prirent en train de faire une farce à s...   \n",
       "\n",
       "                                                       cc  \n",
       "43729   CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "162794  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "75321   CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "20153   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "178246  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6519e315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25084</th>\n",
       "      <td>It was disgusting.</td>\n",
       "      <td>C'était répugnant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26400</th>\n",
       "      <td>This is expensive.</td>\n",
       "      <td>C'est cher.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20670</th>\n",
       "      <td>They all drowned.</td>\n",
       "      <td>Ils se sont tous noyés.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24734</th>\n",
       "      <td>I'm being patient.</td>\n",
       "      <td>Je fais montre de patience.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12921</th>\n",
       "      <td>You're in love.</td>\n",
       "      <td>Tu es amoureuse.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eng                          fra\n",
       "25084  It was disgusting.           C'était répugnant.\n",
       "26400  This is expensive.                  C'est cher.\n",
       "20670   They all drowned.      Ils se sont tous noyés.\n",
       "24734  I'm being patient.  Je fais montre de patience.\n",
       "12921     You're in love.             Tu es amoureuse."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 3만3천개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c85154",
   "metadata": {},
   "source": [
    "# Step 2. 디코더의 문장에 시작 토큰과 종료 토큰을 넣어주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40db3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>Keep still.</td>\n",
       "      <td>\" Restez tranquille ! '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>Throw the dice.</td>\n",
       "      <td>\" Jetez le dé. '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742</th>\n",
       "      <td>I'm a soldier.</td>\n",
       "      <td>\" Je suis soldat. '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5892</th>\n",
       "      <td>That's a lot!</td>\n",
       "      <td>\" C'est beaucoup ! '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>What's inside?</td>\n",
       "      <td>\" Qu'est-ce qu'il y a à l'intérieur ? '</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   eng                                      fra\n",
       "2280       Keep still.                  \" Restez tranquille ! '\n",
       "12055  Throw the dice.                         \" Jetez le dé. '\n",
       "7742    I'm a soldier.                      \" Je suis soldat. '\n",
       "5892     That's a lot!                     \" C'est beaucoup ! '\n",
       "9326    What's inside?  \" Qu'est-ce qu'il y a à l'intérieur ? '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '\"'\n",
    "eos_token = '\\''\n",
    "lines.fra = lines.fra.apply(lambda x : '\" '+ x + ' \\'')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e2781",
   "metadata": {},
   "source": [
    "# Step 1. 정제, 정규화, 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5d1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines.eng)):\n",
    "    lines.eng[i] = lines.eng[i].lower()\n",
    "    lines.eng[i] = re.sub(r\"([?.!,¿])\", r\" \\1\", lines.eng[i]).split()\n",
    "    lines.eng[i].insert(0, '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d85badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18810      [\", i, know, this, song, .]\n",
       "32554    [\", tom, has, been, fired, .]\n",
       "21867        [\", what's, happening, ?]\n",
       "22638      [\", are, you, listening, ?]\n",
       "9201            [\", we're, certain, .]\n",
       "Name: eng, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.eng.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f2d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines.fra)):\n",
    "    lines.fra[i] = lines.fra[i].lower()\n",
    "    lines.fra[i] = re.sub(r\"([?.!,¿])\", r\" \\1\", lines.fra[i]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8c897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835                              [\", je, le, crois, ., ']\n",
       "11828                          [\", c'est, mon, idée, ., ']\n",
       "27544                      [\", où, est, mon, billet, ?, ']\n",
       "20817    [\", elles, sont, en, train, de, gagner, du, te...\n",
       "2079                        [\", j'ai, été, dernière, ., ']\n",
       "Name: fra, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.fra.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25818c29",
   "metadata": {},
   "source": [
    "# Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꿔보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e0204e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 26, 2], [1, 26, 2], [1, 26, 2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level=False)   # 단어 단위로 Tokenizer를 생성합니다. \n",
    "eng_tokenizer.fit_on_texts(lines.eng)               # 50000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00013f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13861</th>\n",
       "      <td>[\", how, did, it, feel, ?]</td>\n",
       "      <td>[\", qu'avez-vous, ressenti, ?, ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26348</th>\n",
       "      <td>[\", they're, surprised, .]</td>\n",
       "      <td>[\", ils, sont, étonnés, ., ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23646</th>\n",
       "      <td>[\", i, appreciate, this, .]</td>\n",
       "      <td>[\", je, l'apprécie, ., ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26936</th>\n",
       "      <td>[\", tom, wants, to, play, .]</td>\n",
       "      <td>[\", tom, veut, jouer, ., ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28485</th>\n",
       "      <td>[\", come, back, in, a, day, .]</td>\n",
       "      <td>[\", revenez, demain, !, ']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  eng                                fra\n",
       "13861      [\", how, did, it, feel, ?]  [\", qu'avez-vous, ressenti, ?, ']\n",
       "26348      [\", they're, surprised, .]      [\", ils, sont, étonnés, ., ']\n",
       "23646     [\", i, appreciate, this, .]          [\", je, l'apprécie, ., ']\n",
       "26936    [\", tom, wants, to, play, .]        [\", tom, veut, jouer, ., ']\n",
       "28485  [\", come, back, in, a, day, .]         [\", revenez, demain, !, ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef738f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 62, 7, 2], [1, 346, 3, 2], [1, 25, 504, 7, 2]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=True)   # 단어 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # 50000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e877d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 4813\n",
      "프랑스어 단어장의 크기 : 9984\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db09fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 8\n",
      "프랑스어 시퀀스의 최대 길이 15\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a883563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4813\n",
      "프랑스어 단어장의 크기 : 9984\n",
      "영어 시퀀스의 최대 길이 8\n",
      "프랑스어 시퀀스의 최대 길이 15\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33f3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ word for word in line if word != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ word for word in line if word != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af2b114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 62, 7], [1, 346, 3], [1, 25, 504, 7]]\n",
      "[[62, 7, 2], [346, 3, 2], [25, 504, 7, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6b81f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 15)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 15)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "993c314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 26  2  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "964f340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 15)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 15)\n"
     ]
    }
   ],
   "source": [
    "#encoder_input = to_categorical(encoder_input)\n",
    "#decoder_input = to_categorical(decoder_input)\n",
    "#decoder_target = to_categorical(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66379292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 15)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 15)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4d76b",
   "metadata": {},
   "source": [
    "# Step 4. 임베딩 층(Embedding layer) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a1b5ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "embedding_size = 512\n",
    "hidden_size = 512\n",
    "\n",
    "# 인코더 LSTM 셀의 마지막 time step의 hidden state와 cell state를 \n",
    "# 디코더 LSTM의 첫 번째 hidden state와 cell state로 전달해준다.\n",
    "\n",
    "# 입력 텐서 생성\n",
    "encoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# 임베딩층 사용\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size)(encoder_inputs)\n",
    "\n",
    "# 마스킹 사용\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "\n",
    "# hidden size가 512인 인코더의 LSTM 셀 생성\n",
    "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
    "\n",
    "# 디코더로 전달할 hidden state, cell state를 리턴, encoder_outputs는 사용하지 않음.\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "\n",
    "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dbb06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 입력 텐서 생성\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# 디코더 임베딩 층 사용\n",
    "dec_emb =  Embedding(fra_vocab_size, hidden_size)(decoder_inputs)\n",
    "\n",
    "# 디코더 마스킹 사용\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# hidden size가 512인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
    "\n",
    "# decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)\n",
    "# initial_state는 LSTM 셀의 초기 상태를 정의하는 인자이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6662df",
   "metadata": {},
   "source": [
    "# Step 5. 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dfefb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')  # 덴스는 단어장 크기로 지정\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a13d3ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 512)    2464256     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 512)    5111808     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 512)    0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 512)    0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 512), (None, 2099200     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 512),  2099200     masking_1[0][0]                  \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 9984)   5121792     lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,896,256\n",
      "Trainable params: 16,896,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'sparse_categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7603302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 18s 48ms/step - loss: 1.7249 - val_loss: 1.6626\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.2029 - val_loss: 1.4475\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.0416 - val_loss: 1.3523\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 0.9388 - val_loss: 1.2689\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 0.8600 - val_loss: 1.2313\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.7964 - val_loss: 1.1869\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.7417 - val_loss: 1.1658\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.6935 - val_loss: 1.1448\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.6515 - val_loss: 1.1304\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.6139 - val_loss: 1.1169\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.5797 - val_loss: 1.1164\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.5486 - val_loss: 1.1084\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.5198 - val_loss: 1.1069\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.4944 - val_loss: 1.1119\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.4726 - val_loss: 1.1100\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.4526 - val_loss: 1.1083\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.4345 - val_loss: 1.1079\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.4185 - val_loss: 1.1150\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.4043 - val_loss: 1.1180\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3907 - val_loss: 1.1256\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3788 - val_loss: 1.1241\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3664 - val_loss: 1.1319\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3548 - val_loss: 1.1284\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3443 - val_loss: 1.1321\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3355 - val_loss: 1.1393\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3277 - val_loss: 1.1447\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3197 - val_loss: 1.1464\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3133 - val_loss: 1.1427\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3071 - val_loss: 1.1488\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.3005 - val_loss: 1.1500\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2954 - val_loss: 1.1576\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2906 - val_loss: 1.1579\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2861 - val_loss: 1.1568\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2821 - val_loss: 1.1536\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2765 - val_loss: 1.1658\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2733 - val_loss: 1.1654\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2702 - val_loss: 1.1743\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2678 - val_loss: 1.1758\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2642 - val_loss: 1.1746\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2616 - val_loss: 1.1815\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2582 - val_loss: 1.1852\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2556 - val_loss: 1.1873\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2528 - val_loss: 1.1890\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2497 - val_loss: 1.1829\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2463 - val_loss: 1.1914\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2438 - val_loss: 1.1924\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2411 - val_loss: 1.1886\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2386 - val_loss: 1.1973\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2359 - val_loss: 1.1982\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 0.2339 - val_loss: 1.1919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train,\n",
    "                    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                    batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cea2f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "history_dict=history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56cfad84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(val_loss) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35e6a450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, None, 512)         2464256   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                [(None, 512), (None, 512) 2099200   \n",
      "=================================================================\n",
      "Total params: 4,563,456\n",
      "Trainable params: 4,563,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계시 생성했던 encoder_inputs(=입력 텐서)(encoder_inputs = Input(shape=(None, eng_vocab_size)))와\n",
    "# hidden state와 cell state를 다음 time step으로 전달하기 위해 별도 저장했던 encoder_states(encoder_states = [state_h, state_c])를 재사용한다.\n",
    "\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0519a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "dec_emb_test =  Embedding(fra_vocab_size, hidden_size)(decoder_inputs)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb_test, initial_state = decoder_states_inputs)\n",
    "\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6267b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 512)    5111808     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 512),  2099200     embedding_7[0][0]                \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 9984)   5121792     lstm_6[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 12,332,800\n",
      "Trainable params: 12,332,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs = [decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54902e35",
   "metadata": {},
   "source": [
    "# Step 6. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e690a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 만들어 두었던 사전을 간단한 변수로 다시 정의\n",
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b931c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # <SOS>에 해당하는 정수 생성\n",
    "  target_seq = np.zeros((1,1))\n",
    "  target_seq[0, 0] = fra2idx['\"']\n",
    "\n",
    "  stop_condition = False\n",
    "  decoded_sentence = ''\n",
    "\n",
    "  # stop_condition이 True가 될 때까지 루프 반복\n",
    "  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "  while not stop_condition:\n",
    "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    # 예측 결과를 단어로 변환\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "    # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "    decoded_sentence += ' '+sampled_char\n",
    "\n",
    "    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "    if (sampled_char == '\\'' or\n",
    "        len(decoded_sentence) > max_fra_seq_len):\n",
    "        stop_condition = True\n",
    "\n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "    states_value = [h, c]\n",
    "\n",
    "  return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d264181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0):\n",
    "      sentence = sentence + idx2eng[encoded_word] + ' '\n",
    "  return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0 and encoded_word != fra2idx['\"'] and encoded_word != fra2idx['\\'']):\n",
    "      sentence = sentence + idx2fra[encoded_word] + ' '\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf6a9125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : \" i left . \n",
      "정답문장 : je suis partie . \n",
      "번역문장 : j'y suis . \n",
      "--------------------------------------------------\n",
      "입력문장 : \" come on . \n",
      "정답문장 : venez ! \n",
      "번역문장 : venez ! ! \n",
      "--------------------------------------------------\n",
      "입력문장 : \" i stood . \n",
      "정답문장 : je me suis tenue debout . \n",
      "번역문장 : je me les \n",
      "--------------------------------------------------\n",
      "입력문장 : \" you run . \n",
      "정답문장 : tu cours . \n",
      "번역문장 : tu . . . . \n",
      "--------------------------------------------------\n",
      "입력문장 : \" go ahead ! \n",
      "정답문장 : avance ! \n",
      "번역문장 : en . ! ! ! \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 입력 문장의 인덱스\n",
    "for seq_index in [111, 222, 333, 444, 555]:\n",
    "  input_seq = encoder_input[seq_index: seq_index+1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
    "  print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
